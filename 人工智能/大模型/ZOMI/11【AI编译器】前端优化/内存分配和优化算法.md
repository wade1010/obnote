![](https://gitee.com/hxc8/images1/raw/master/img/202407172118955.jpg)

模型和硬件的内存演进

内存的划分与复用好处

节省内存的算法

 

![](https://gitee.com/hxc8/images1/raw/master/img/202407172118071.jpg)

![](https://gitee.com/hxc8/images1/raw/master/img/202407172118098.jpg)

深度学习的整个训练流程里面，第一个就是输入的数据都要塞到内存里面，在具体的训练当中，还要塞进去神经网络，又包括正向的神经网络的图，也包括反向的神经网络的图，正反向加起来，内存空间就变大了，所以说大部分内存空间消耗在数据还有网络模型里面。

![](https://gitee.com/hxc8/images1/raw/master/img/202407172118213.jpg)

![](https://gitee.com/hxc8/images1/raw/master/img/202407172118200.jpg)

![](https://gitee.com/hxc8/images1/raw/master/img/202407172118793.jpg)

![](https://gitee.com/hxc8/images1/raw/master/img/202407172118770.jpg)

![](https://gitee.com/hxc8/images1/raw/master/img/202407172119786.jpg)

空间换内存，其实在传统的一些程序里面，用的也很多，在AI或者深度学习里面，一般都会做一些CPU的offload，就是把NPU或者芯片的内存空间丢给CPU，可能它临时用不到这一个模块，那就直接卸载到CPU里面，这种算法更多的是针对MOE的一些算法结构，就是 multi of expert的这种算法或者模型结构，去做一个优化。

计算换内存，最重要的一个算法就是gradient checkpointing，叫做重计算。很多时候，如果把一些计算的中间结果存在内存空间，需要把ALU（计算单元）里面算出来的结果，存到内存空间，这里面传输速率就很重要了， 假设重算一遍的速率比读取数据的效率要高，肯定选择重新算一遍。做一些大模型的时候计算换内存也是非常常用的算法优化。

模型压缩，在端侧推理的时候特别常用。例如做一些低比特量化的一些工作，还有模型剪枝，模型蒸馏相关的一些算法，这些都是内存节省的一些算法

内存复用：

替代操作

内存共享

![](https://gitee.com/hxc8/images1/raw/master/img/202407172119780.jpg)

上图final memory plan，因为它不是实际执行的，而是一个预执行预分配的工作，可以看到不同的颜色代表不同的内存分配的模块和内存分配的空间，三个红色就可以各自去进行一个复用，而中间绿和蓝确实就没办法进行复用了，这个就是最原始的一个内存优化方法。