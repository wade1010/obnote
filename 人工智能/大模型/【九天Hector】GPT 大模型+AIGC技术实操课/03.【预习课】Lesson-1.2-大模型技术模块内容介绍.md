- 摘要

该视频主要介绍了开源大模型，包括glm、check glm、llama、meta、7b、most和迷你gpt 4等模型。其中重点讲解了check glm模型，介绍了其具备的60亿个参数和解决问题的能力。同时，还介绍了DeepSpeedChat只能训练某一种类型的大模型，并介绍了在没有GPU的情况下如何获取云端的算力来进行部署。最后，提到了大模型应用工程师的岗位，需要能够微调、部署大模型，并进行定制化训练。

- 总结

**大模型技术概述**

1.开源大模型是免费可调用的，支持本地部署，也可从零开始训练。2.技术细节和语料库公开，便于研究和应用。3.推荐使用GLM模型，由清华大学团队开发，拥有60亿参数。4.GLM模型基于质朴AI公司的GLiM130B模型修改，具有较低使用门槛和良好的中文识别能力。

03:53**开源大模型推荐与比较**

1.推荐使用Chat GLM模型，因其使用门槛低且能良好识别中文对话。2.LLAMA模型参数可调整，性能好但使用复杂，适合有经验的研究者。3.阿帕卡（Alpaca）和MOSS模型基于LLAMA训练，性能接近GPT-3.5，但中文支持有限。4.迷你GPT 4模型具备多模态功能，显示了大模型技术在个人计算设备上的应用潜力。

12:10**Deep Speed Chat工具介绍**

1.Deep Speed Chat是微软推出的训练大模型的工具，支持一键部署和云端训练。2.提供自定义参数规模和训练语料功能，适用于定制化大模型训练。3.云端训练费用相对较低，能高效训练大模型，适用于预算有限的研究者。

16:20**开源大模型学习策略**

1.学习开源大模型需考虑中文效果、显存要求和安装部署便利性。2.Chat GLM 6b和Deep Speed Chat是正式课程重点介绍的内容。3.其他工具将通过公开课或预习课介绍安装部署操作。

19:51**大模型应用工程师岗位介绍**

1.大模型应用工程师是新兴技术岗位，要求微调、部署和定制化训练大模型。2.岗位职责包括开源大模型训练、GPT模型微调和使用Deep Speed Chat进行定制化模型训练。3.大模型应用工程师岗位需求反映了AI技术浪潮下新兴技术岗位的需求增长。