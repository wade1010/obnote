# 信息检索(IR)
## 传统方法
### BM25 (Best Matching 25)
![image.png](https://gitee.com/hxc8/images10/raw/master/img/202408051408703.png)
### TF(Term Frequency)
词频，就是query中每个词，在这个文档中出现的频率，就是一个简单的统计。
如果一篇文档中 ，它这个词汇匹配率，与这个查询的词汇匹配率越高的话，就可以认为这篇文档与这个查询的相关程度越高。

### IDF（Inverse Document Frequency）
你文档频率，用于评估查询中一个词汇在所有文档中常见或者稀有程度，比如一根词在所有文档中都很常见，它的IDF打分反而会很低。如果IDF分数高的话，反向说明这个查询词，可以它包含的信息比较大，也更重要。
## 传统IR存在的问题
### 1、词汇失配
我们会用不同的词汇表达相同的意思。
![image.png](https://gitee.com/hxc8/images10/raw/master/img/202408051421713.png)

### 2、语义失配
即文档跟我们查询之间即使存在很高的词汇匹配率，但描述的含义却完全不一样。
![image.png](https://gitee.com/hxc8/images10/raw/master/img/202408051421330.png)
## Neural IR
使用神经网络，将用户的查询和文档库中的文档投射到同一个向量空间，然后再去预测两则相关性的分数，从而避免了传统IR中词汇失配合语义失配的问题。

### 基于大模型的IR架构
![image.png](https://gitee.com/hxc8/images10/raw/master/img/202408051431109.png)

通常会在re-ranking的阶段采用cross-encoder的大模型架构

### Cross-Encoder


### Dual-Encoder
