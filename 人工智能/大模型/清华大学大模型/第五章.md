## 数据并行

![image.png](https://gitee.com/hxc8/images9/raw/master/img/202408031220852.png)
上图，把数据切为3份，每张显卡处理一部分数据，每张显卡利用得到的数据进行前向传播和反向传播，得到各自的梯度，为了让模型学到这份数据的所有知识，就需要把这些梯度的信息进行一个聚合，也就是取平均的操作。那么我们得到聚合好的参数去更新模型，就能学到切分3部分数据合起来的完整的数据的知识。
具体来说：在数据并行的过程中，我们有一个参数服务器，里面保存了模型的参数，还有完整的一批数据，前向传播的过程中，参数服务器上的参数，会被复制到所有的显卡上，每张显卡上都得到了很参数服务器上一样的模型参数，然后把数据切分为3份，每张显卡上各拿到一部分数据，然后每张显卡用完整的模型参数和一部分的数据去进行前向传播和反向传播，我们就能够得到每张显卡上各自的梯度，最后将这个梯度进行聚合，将聚合后的梯度传回我们的参数服务器。那么参数服务器上面有了原始的模型参数和这个聚合好的模型的完整的梯度，我们就可以用优化器去对模型的参数进行更新，那么更新后的参数又会进入下一轮的模型的训练迭代

## 集合通信

1. broadcast
   把数据从一张显卡传到其它所有的显卡上
2. reduce
   规约可以是求和、平均、MAX等，把各张显卡上的数据 
3. 