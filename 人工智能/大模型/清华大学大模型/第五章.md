## 数据并行

![image.png](https://gitee.com/hxc8/images9/raw/master/img/202408031220852.png)
上图，把数据切为3份，每张显卡处理一部分数据，每张显卡利用得到的数据进行前向传播和反向传播，得到各自的梯度，为了让模型学到这份数据的所有知识，就需要把这些梯度的信息进行一个聚合，也就是取平均的操作。那么我们得到聚合好的参数去更新模型，就能学到切分3部分数据合起来的完整的数据的知识。
具体来说：在数据并行的过程中，我们有一个参数服务器，里面保存了模型的参数，还有完整的一批数据，前向传播的过程中，参数服务器上的参数，会被复制到所有的显卡上，每张显卡上都得到了很参数服务器上一样的模型参数，然后把数据切分为3份，每张显卡上各拿到一部分数据，然后每张显卡用完整的模型参数和一部分的数据去进行前向传播和反向传播，我们就能够得到每张显卡上各自的梯度，最后将这个梯度进行聚合，将聚合后的梯度传回我们的参数服务器。那么参数服务器上面有了原始的模型参数和这个聚合好的模型的完整的梯度，我们就可以用优化器去对模型的参数进行更新，那么更新后的参数又会进入下一轮的模型的训练迭代

### 集合通信

1. broadcast
   把数据从一张显卡传到其它所有的显卡上
2. reduce
   规约可以是求和、平均、MAX等，把各张显卡上的数据进行一个规约，然后把规约得到的结果，放到我们其中一张指定的显卡里面。 
3. all reduce
   和reduce几乎相同，不同点就是把结果发送到所有显卡上面（reduce是发送到指定的一张显卡上）
4. reduce scatter
   跟all reduce相比，相同之处是它们都把规约得到的结果发给所有显卡，不同之处在于，reduce scatter，最后每张显卡上只得到一部分的规约结果。![image.png](https://gitee.com/hxc8/images9/raw/master/img/202408031236427.png)
如上图，0号显卡，会得到in0的前1/4的参数，加上in1的前1/4的参数，加上in2的前1/4的参数，加上in3的前1/4的参数，得到out0。其他同理。
5. all gather
   可以跟all reduce类比下，把各张显卡上的数据进行收集，然后进行一个拼接，然后广播到所有显卡上，所有显卡得到了一个搜集后的结果。![image.png](https://gitee.com/hxc8/images9/raw/master/img/202408031244132.png)
## 分布式数据并行
对数据并行进行了优化，没有参数服务器。
每张显卡各自完成参数更新。然后保证参数更新后的结果一致。![image.png](https://gitee.com/hxc8/images9/raw/master/img/202408031247934.png)

## 数据并行显存优化
计算过程的中间结果是跟batch乘以句子长度和模型维度相关的一个显存占用。使用数据并行的时候，把一批数据分成了N份，让每张显卡只处理其中的一部分数据，等效于每张显卡上所处理的batch的大小将变成了原来显卡数分之一，那么通过把这个输入的维度进行了一个降低，那我们模型整体的中间结果量（每张卡），也进行了一个降低。 
但是这个方法有一个缺点，就是为了支持模型的训练，它至少需要训练1条数据，最极端情况下，每张显卡只得到一个数据的时候，由于我们的参数哈需要完整的保存在显卡上，梯度也需要完整保存在显卡上，优化器也需要完整保存在显卡上，那么即使中间结果一点都不在显卡上，我们模型仍然有可能无法在一张显卡上进行计算。

## 模型并行
一张显卡无法放下模型的所有参数、所有梯度、所有优化器，就想办法把一个模型分成很多个小部分![image.png](https://gitee.com/hxc8/images9/raw/master/img/202408031332289.png)
思路：针对线性层的矩阵乘法的例子，上图左上角，3行2列的矩阵乘以2行1列的矩阵，本质上可以把它的结果分成三个 部分。
可以把3X2的矩阵看成线性层的参数W，把2X1向量看成线性层的输入。
![image.png](https://gitee.com/hxc8/images9/raw/master/img/202408031335370.png)
通过上面的方法，我们的线性层的参数，就可以划分到多张显卡上。而且我们需要保证多张显卡上模型的输入是一样的。那么我们就不能使用数据并行的那一套方式对数据进行划分了，我们需要保证每一张显卡上得到的输入是一样的，所以他们是同一批数据。
得到多个子结果，然后使用all gather收集算子。
模型并行对显存的优化：首先，每张显卡只需要保存原来N分之一的模型参数，N是我们GPU的个数。由于每张卡只保留一部分参数，梯度、优化器也只用保存对应的一部分（变少了）。
由于这个矩阵乘法，需要保证数据的输入是一致的，不能使用数据并行的那一套，去把数据切分成很多个小份，因此我们模型的计算的中间结果实际上是没有减少的，这也是这个方法所带来的弊端。既然我们的中间结果无法减小，当batch size开的比较大的时候，仍然会出现显存溢出的问题。

## ZeRO
### ZeRO-Stage1
![image.png](https://gitee.com/hxc8/images9/raw/master/img/202408031404110.png)
基于数据并行建立起的一套框架。

数据并行之中，需要对模型的梯度进行规约，为了保证每一轮迭代之后，每张显卡上得到参数仍然是一致的，我们就让每一张显卡上都得到了规约后的参数。然后每张显卡各自去进行参数的更新。可以发现1号显卡用的事同样一批参数和梯度去进行参数的更新，而2号显卡也是用的同样的一批参数和梯度。其实所有卡用的都是同样一批参数和梯度，他们各自去进行参数优化是不是就带来了计算上的重复和冗余。

为了消除这个样的冗余，提出的方法就是（上图下半部分）每张显卡上只获得一部分的梯度，然后只去更新一部分的参数，这样我们各张显卡可以合作，每张显卡只更新一部分的参数，最后他们进行一个交流，就能把这个模型的完整梯度给恢复出来。

完整过程如下：
![image.png](https://gitee.com/hxc8/images9/raw/master/img/202408031422476.png)
 由于是基于数据并行的架构，那么它仍然是每张显卡上保存完整的模型参数，然后有一部分的数据，通过前向传播和反向传播的到各自的梯度，从这之后的步骤开始就不一样了，它不是使用all  reduce让每张显卡得到想通规约后的梯度，而是使用reduce scatter，是让每张显卡得到一部分的结果，比如1号显卡得到了规约后的梯度的前1/3，2号显卡得到了规约后的梯度的中间1/3，3号显卡得到了规约后的梯度的后1/3。
 我们可以让1号显卡用这前1/3的梯度和前1/3的梯度对应的optimizer，去更新前1/3的模型的参数。然后2、3号显卡同理。每张显卡各自更新得到了一部分的模型参数之后，我们需要通过一个收集的操作，把各显卡分工合作的结果进行一个收集后，再进行一个拼接。拼接之后的结果通过All,把这它告诉所有的显卡，经过这样的操作之后，每张显卡上又得到了完全一样的参数和一致的结果。

### ZeRO-Stage2
![image.png](https://gitee.com/hxc8/images9/raw/master/img/202408031433335.png)
stage2进行了一个优化，在stage1中，需要再反向传播得到所有的梯度之后，对这个梯度进行reduce scatter，那我们reduce scatter之后，每张显卡上各自得到了一部分规约后的梯度。得到这个gradient\*之后，原来的gradient实际上是不需要保存在显卡上了，因为后面参数更新的过程中，优化器只需要用到gradient\*去进行一个参数的优化，那么这部分gradient其实已经可以从显存中移除。

###### 什么时候移除呢？
stage1阶段，在反向传播结束之后，才去把这个gradient移除。那可不可以在这个反向传播的过程中，就把gradient\*提前算出来，然后把这个gradient删掉呢？具体来说，假如有一个24层的transformer，在反向传播结束第24层的时候，就用第24层各卡上的梯度进行一个reduce scatter，之后，第24层的梯度就可以不要了，到第23层的时候，计算第23层各卡上的模型梯度，进行一个reduce scatter，得到那一层的gradient\*，这个时候，就又可以只保存第23层的gradient\*到显卡上，然后把第23层的gradient从显卡上移除。通过这样的操作，把gradient\*从显卡上移除的操作提前了，就可以进一步节省显存空间。

### ZeRO-Stage3
![image.png](https://gitee.com/hxc8/images9/raw/master/img/202408031448955.png)
这个阶段对模型的参数进行了进一步的划分，在stage1和stage2中，都没有避免前面模型并行所解决的那个问题(模型的参数仍然要完整的保存在我们的显卡里面)，前面也计算过11B的模型，它保存在显卡里面就已占用了约40GB的显存。

为了解决这个问题，就需要把模型的参数也进行一个划分，因为每张显卡上只保留了一部分的梯度去进行参数更新，参数更新也只更新一部分的模型的参数，那么我们实际上每张显卡就可以只保存它自己参数更新所负责的那一部分参数，那么每张显卡上就会只有一部分的参数和一部分的数据、一部分的梯度和一部分的优化器。
那么每张卡上只有一部分模型参数，怎么进行模型的前向传播、反向传播呢？这两个过程中，需要把模型的参数进行一个all gather的操作。在用到模型参数的时候，我们去临时把每张卡上的那一部分参数进行一个收集拼接，当我们用完的时候，就把这个参数从显卡中释放。

具体而言，在transformer中一个线性层，这个线性层的参数可能被分到3张显卡上，需要计算这个线性层的时候，临时把跟这个线性层有关的一部分参数从各张显卡上收集起来，进行一个线性层的计算，进行完这一层线性层计算之后，模型参数就不需要放在显卡里了，又可以释放掉了，又恢复层每张显卡只保留一部分线性层参数的状态。

需要注意的是，使用这样的方式，我们在方向传播计算模型梯度的时候，实际上也需要用到模型的完整的参数，也是需要gather操作。相比stage2来说（它只在参数更新那一步进行了all gather操作），而在stage3中，它虽然在阐述更新的时候没有使用all gather，但是它在前向传播和反向传播的时候，各需要使用一次all gather，实际上是增加了一次通信，相比stage2，stage3是一个用时间换空间的一个算法。

## 显存分析
⚠️upload failed, check dev console
