 提示语工程可以分为“零样本学习（Zero-Shot Learning）”和“少样本学习（Few-Shot Learning）”。

零样本学习就是直接将模型需要处理的任务，通过提示语提供给模型，并要求模型输出结果。而少样本学习则会为模型提供例子，具体就是一组在目标任务上的高质量示例，通常每个示例都包括一组目标的输入和输出。

在AIGC系统中，如果你的提示引擎直接将用户输入的问题传递给LLM，那用的就是 Zero-Shot 的处理方法。最早期的ChatGPT采用了这种方法，它会直接将用户的输入内容“透传”给大型语言模型。

不过在早期的这种“简陋”的使用条件下，一些对提示语工程有所了解的用户也会在问题前为大语言模型提供一些示例，手动把它变成 Few-Shot 提示语。

然而，这时用户只能基于自己的使用经验来选择更合适的提示词，但这种靠猜测试探的方式升高了大语言模型的使用门槛。

因此，大模型系统会根据不同用户的使用记录，自行判断哪类提示词对自家模型更友好。在提示与长度限制相对宽松的情况下，系统还会自动使用Few-Shot的形式帮助用户使用更加友好的提示词来优化提示语质量。

我们稍微总结一下，**提示语工程的核心目标是，基于ICL的特点为LLM选择适当的Few-Shot示例样本。**

## 提示语工程设计

理解了前面的概念，你应该已经意识到了，提示语工程最重要的是后面这两个问题。

1. 为模型提供外部知识，也就是通过示例样本来进行少样本学习（Few-Shot Learning）。

1. 让模型理解指令任务，通过提示语策略，帮助模型解决复杂问题。

我们先来讨论第一个问题，那就是如何为模型提供有效的示例样本。在术语上的说法则是优选（Selecting）。

### 优选（Selecting）

为模型优选示例样本的过程，其实就是围绕着用户输入的问题，为模型收集高质量数据的过程。你可以试着回想一下，在AIRC系统中你是如何收集高质量数据的呢？

没错，是通过召回和排序完成的，其中召回过程需要使用向量引擎，内容标签倒排索引和知识图谱等知识表达和知识检索方法。

其实在提示引擎中我们第一步要做的工作就是围绕用户的需求，去检索这些最重要的外部数据。这个检索和你之前学过的AIRC系统中的知识是一模一样的。

你同样需要将最优质的内容排在前面，因为大模型所能接受的 prompt 是有限的，你只能在海量的内容中优选最重要的内容，来作为提示词的一部分。具体怎么排序我们接着往下看。

### 排序（Ordering）

在选择最合适的提示样本后，我们需要进一步对其进行二次加工，这个加工过程是AIGC系统独有的“重排”模块，用于优化提示的内容。

因为业界的实践表明，在某些测试中，不同排序的示例可能导致生成内容的质量大幅波动。因此，除了示例样本的选取之外，示例的排序也会影响提示工程的有效性。

目前，主要有一种常见的工业界使用的排序策略，也是最低成本的策略，那就是基于示例质量的排序，这个方法非常直接，只需要将质量较高的示例样本排在后面，以靠近问题输入的位置。除此之外，还有一些相对复杂的基于熵的排序方法，这个我们将在下节课进行学习。

### 可信AI（Trustworthy AI）

之前说过，提示语引擎其实一定程度上就是智能体的“本体”。所以LLM的输入，也就是提示词，以及输出也就是生成内容都需要由提示语引擎来负责。因此，现在工业界在AIGC系统的链路就是：检索 -> 生成 -> 检索的形态。你可能会问了，检索到生成的这个过程我倒是理解，可是为什么生成后面还会再加一个检索呢？

很好的问题，这是因为两次检索的目标是不同的。第一次检索的输入是用户问题，目的是为大语言模型提供外部记忆；而第二次检索的输入则是生成内容，目的是为生成的内容提供引用信息，增加生成内容的可信度，此外，还我们可以通过这次检索，来优选生成模型输出的多个结果。

### 推理步骤（Reasoning Steps）

现在，你已经知道了该如何为大语言模型提供有效的示例样本。接下来，我们再来聊聊怎样通过提示语策略，帮助模型解决复杂问题。我们将用一些思维链方法帮助模型把大事化小。

首先，让我们回顾一下思维链（Chain-of-Thought，CoT）的概念。CoT是一种用于引导大语言模型进行推理的方法。CoT通过提示词指示模型，生成一系列简短的句子来给出推理步骤。

在 [第16节课](https://time.geekbang.org/column/article/701454) 中我们学习过，工业界在实践中发现，经过代码语料训练过的LLM具有更强的 CoT 能力。在 [第17节课](https://time.geekbang.org/column/article/701952)，也就是“涌现”原理的那节课里我们也提过，CoT 的优势在复杂的推理任务更明显，在使用大参数模型（比如 50B以上的模型）时，这个优势则更明显。

CoT 提示可以约束大语言模型理解和遵循推理逻辑，从而提高推理任务的准确性。虽然 CoT 可以用一些动态的步骤生成答案，但是还是存在一些局限性。这就催生出了很多方法来优化 CoT 的过程，比如我们下节课马上要学习的自一致采样（Self-Consistency Sampling）。