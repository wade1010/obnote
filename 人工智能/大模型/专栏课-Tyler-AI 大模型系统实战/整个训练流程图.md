 

![](https://gitee.com/hxc8/images0/raw/master/img/202407172041305.jpg)

首先，我们通过比较容易获得的公开无标签数据，来训练一个大语言模型，比如 GPT-3，这是我们在前几节课就已经学过的知识。然后，通过人工编写的问答对，来生成高质量的监督对话数据，来优化大语言模型的对话能力。

在得到了这个优化后模型之后，标注者便在给定问题上可以基于模型生成的答案，对回答进行排序，并用排序数据训练一个奖励模型对回答的结果排序打分，用来评估回答的质量。

看到 **“排序打分”** 这个词，你是不是特别熟悉？没错，这里的排序打分和你在 AIRC 系统中所学习的排序打分方法没有任何区别，只不过它使用了 Learning to Rank 方法来训练这个打分模型，这个方法早已广泛使用在了 AIRC 系统当中。

这里我们这就来看看 Learning to Rank 方法的原理。这个方法很直观，其实就是对偏序关系进行建模，借助偏序关系的传递性，进一步对全局的偏序关系建模。你可以借助这个方法的损失函数直观理解它的原理。

![](https://gitee.com/hxc8/images0/raw/master/img/202407172041704.jpg)

![](https://gitee.com/hxc8/images0/raw/master/img/202407172041515.jpg)