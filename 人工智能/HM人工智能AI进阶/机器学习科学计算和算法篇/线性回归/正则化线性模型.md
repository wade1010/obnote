正则化线性模型介绍：

- Ridge Regression 岭回归

- Lasso 回归

- Elastic Net 弹性网络

- Early stopping

## 1 岭回归

岭回归(Ridge Regression ，又名 Tikhonov regularization)是线性回归的正则化版本，即在原来的线性回归的cost function 中添加正则项（regularization term）

![](https://gitee.com/hxc8/images1/raw/master/img/202407172144476.jpg)

以达到在拟合数据的同时，使模型权重尽可能小的目的,岭回归代价函数:

![](https://gitee.com/hxc8/images1/raw/master/img/202407172144355.jpg)

- **α=0：岭回归退化为线性回归**

## 2 Lasso 回归

Lasso 回归(Lasso Regression)是线性回归的另一种正则化版本，正则项为权值向量的ℓ1范数。

Lasso回归的代价函数 ：

![](https://gitee.com/hxc8/images1/raw/master/img/202407172144216.jpg)

【注意 】

- Lasso Regression 的代价函数在 θi=0处是不可导的.

- 解决方法：在θi=0处用一个次梯度向量(subgradient vector)代替梯度，如下式

- Lasso Regression 的次梯度向量

![](https://gitee.com/hxc8/images1/raw/master/img/202407172144624.jpg)

Lasso Regression 有一个很重要的性质是：倾向于完全消除不重要的权重。

例如：当α 取值相对较大时，高阶多项式退化为二次甚至是线性：高阶多项式特征的权重被置为0。

也就是说，Lasso Regression 能够自动进行特征选择，并输出一个稀疏模型（只有少数特征的权重是非零的）。

## 3 弹性网络

弹性网络(Elastic Net)在岭回归和Lasso回归中进行了折中，通过 **混合比(mix ratio) r** 进行控制：

- r=0：弹性网络变为岭回归

- r=1：弹性网络便为Lasso回归

弹性网络的代价函数 ：

![](https://gitee.com/hxc8/images1/raw/master/img/202407172144450.jpg)

一般来说，我们应避免使用**朴素线性回归**，而应对模型进行一定的正则化处理，那如何选择正则化方法呢？

**小结：**

- 常用：岭回归

- 假设只有少部分特征是有用的：

	- 弹性网络

	- Lasso

	- 一般来说，弹性网络的使用更为广泛。因为在特征维度高于训练样本数，或者特征是强相关的情况下，Lasso回归的表现不太稳定。

- api:

```python
from sklearn.linear_model import Ridge, ElasticNet, Lasso

```

## 4 Early Stopping [了解]

Early Stopping 也是正则化迭代学习的方法之一。

其做法为：在验证错误率达到最小值的时候停止训练。

## 5 小结

- Ridge Regression 岭回归 

	- 就是把系数添加平方项

	- 然后限制系数值的大小

	- **α值越小，系数值越大，α越大，系数值越小**

- Lasso 回归

	- 对系数值进行绝对值处理

	- **由于绝对值在顶点处不可导**，所以进行计算的过程中产生很多0，最后得到结果为：稀疏矩阵

- Elastic Net 弹性网络

	- 是前两个内容的综合

	- 设置了一个r,如果r=0--岭回归；r=1--Lasso回归

- Early stopping

	- 通过限制错误率的阈值，进行停止