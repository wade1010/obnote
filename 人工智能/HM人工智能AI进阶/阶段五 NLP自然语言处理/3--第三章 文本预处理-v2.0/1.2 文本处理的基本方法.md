### 学习目标

- 了解什么是分词, 词性标注, 命名实体识别及其它们的作用.

- 掌握分词, 词性标注, 命名实体识别流行工具的使用方法.

### 什么是分词

- 分词就是将连续的字序列按照一定的规范重新组合成词序列的过程。我们知道，在英文的行文中，单词之间是以空格作为自然分界符的，而中文只是字、句和段能通过明显的分界符来简单划界，唯独词没有一个形式上的分界符, 分词过程就是找到这样分界符的过程.

- 举个栗子:

```
工信处女干事每月经过下属科室都要亲口交代24口交换机等技术性器件的安装工作 

==> 

['工信处', '女干事', '每月', '经过', '下属', '科室', '都', '要', '亲口', '交代', '24', '口', '交换机', '等', '技术性', '器件', '的', '安装', '工作']

```

- 分词的作用:

	- 词作为语言语义理解的最小单元, 是人类理解文本语言的基础. 因此也是AI解决NLP领域高阶任务, 如自动问答, 机器翻译, 文本生成的重要基础环节.

- 流行中文分词工具jieba:

	- 愿景: “结巴”中文分词, 做最好的 Python 中文分词组件.

- jieba的特性:

	- 支持多种分词模式

> 精确模式全模式搜索引擎模式


	- 支持中文繁体分词

	- 支持用户自定义词典

- jieba的安装:

```
pip install jieba

```

- jieba的使用:

> 精确模式分词:试图将句子最精确地切开，适合文本分析.


```
>>> import jieba
>>> content = "工信处女干事每月经过下属科室都要亲口交代24口交换机等技术性器件的安装工作"
>>> jieba.cut(content, cut_all=False)  # cut_all默认为False

# 将返回一个生成器对象
<generator object Tokenizer.cut at 0x7f065c19e318>

# 若需直接返回列表内容, 使用jieba.lcut即可
>>> jieba.lcut(content, cut_all=False)
['工信处', '女干事', '每月', '经过', '下属', '科室', '都', '要', '亲口', '交代', '24', '口', '交换机', '等', '技术性', '器件', '的', '安装', '工作']

```

> 全模式分词:把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能消除 歧义.


```
>>> import jieba
>>> content = "工信处女干事每月经过下属科室都要亲口交代24口交换机等技术性器件的安装工作"
>>> jieba.cut(content, cut_all=True)  # cut_all默认为False

# 将返回一个生成器对象
<generator object Tokenizer.cut at 0x7f065c19e318>

# 若需直接返回列表内容, 使用jieba.lcut即可
>>> jieba.lcut(content, cut_all=True)
['工信处', '处女', '女干事', '干事', '每月', '月经', '经过', '下属', '科室', '都', '要', '亲口', '口交', '交代', '24', '口交', '交换', '交换机', '换机', '等', '技术', '技术性', '性器', '器件', '的', '安装', '安装工', '装工', '工作']

```

> 搜索引擎模式分词:在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词.


```
>>> import jieba
>>> content = "工信处女干事每月经过下属科室都要亲口交代24口交换机等技术性器件的安装工作"
>>> jieba.cut_for_search(content)

# 将返回一个生成器对象
<generator object Tokenizer.cut at 0x7f065c19e318>

# 若需直接返回列表内容, 使用jieba.lcut_for_search即可
>>> jieba.lcut_for_search(content)
['工信处', '干事', '女干事', '每月', '经过', '下属', '科室', '都', '要', '亲口', '交代', '24', '口', '交换', '换机', '交换机', '等', '技术', '技术性', '器件', '的', '安装', '工作']

# 对'女干事', '交换机'等较长词汇都进行了再次分词.

```

> 中文繁体分词:针对中国香港, 台湾地区的繁体文本进行分词.


```
>>> import jieba
>>> content = "煩惱即是菩提，我暫且不提"
>>> jieba.lcut(content)
['煩惱', '即', '是', '菩提', '，', '我', '暫且', '不', '提']

```

> 使用用户自定义词典:添加自定义词典后, jieba能够准确识别词典中出现的词汇，提升整体的识别准确率.词典格式: 每一行分三部分：词语、词频（可省略）、词性（可省略），用空格隔开，顺序不可颠倒.词典样式如下, 具体词性含义请参照附录: jieba词性对照表, 将该词典存为userdict.txt, 方便之后加载使用.


```
云计算 5 n
李小福 2 nr
easy_install 3 eng
好用 300
韩玉赏鉴 3 nz
八一双鹿 3 nz

```

```
>>> import jieba
>>> jieba.lcut("八一双鹿更名为八一南昌篮球队！")
# 没有使用用户自定义词典前的结果:
>>> ['八', '一双', '鹿', '更名', '为', '八一', '南昌', '篮球队', '！']


>>> jieba.load_userdict("./userdict.txt")
# 使用了用户自定义词典后的结果:
['八一双鹿', '更名', '为', '八一', '南昌', '篮球队', '！']

```

### 什么是命名实体识别

- 命名实体: 通常我们将人名, 地名, 机构名等专有名词统称命名实体. 如: 周杰伦, 黑山县, 孔子学院, 24辊方钢矫直机.

- 顾名思义, 命名实体识别(Named Entity Recognition，简称NER)就是识别出一段文本中可能存在的命名实体.

- 举个栗子:

```
鲁迅, 浙江绍兴人, 五四新文化运动的重要参与者, 代表作朝花夕拾.

==>

鲁迅(人名) / 浙江绍兴(地名)人 / 五四新文化运动(专有名词) / 重要参与者 / 代表作 / 朝花夕拾(专有名词)

```

- 命名实体识别的作用:

	- 同词汇一样, 命名实体也是人类理解文本的基础单元, 因此也是AI解决NLP领域高阶任务的重要基础环节.

### 什么是词性标注

- 词性: 语言中对词的一种分类方法，以语法特征为主要依据、兼顾词汇意义对词进行划分的结果, 常见的词性有14种, 如: 名词, 动词, 形容词等.

- 顾名思义, 词性标注(Part-Of-Speech tagging, 简称POS)就是标注出一段文本中每个词汇的词性.

- 举个栗子:

```
我爱自然语言处理

==>

我/rr, 爱/v, 自然语言/n, 处理/vn

rr: 人称代词
v: 动词
n: 名词
vn: 动名词

```

- 词性标注的作用:

	- 词性标注以分词为基础, 是对文本语言的另一个角度的理解, 因此也常常成为AI解决NLP领域高阶任务的重要基础环节.

- 使用jieba进行中文词性标注:

```
>>> import jieba.posseg as pseg
>>> pseg.lcut("我爱北京天安门") 
[pair('我', 'r'), pair('爱', 'v'), pair('北京', 'ns'), pair('天安门', 'ns')]

# 结果返回一个装有pair元组的列表, 每个pair元组中分别是词汇及其对应的词性, 具体词性含义请参照[附录: jieba词性对照表]()

```

### 小节总结

- 学习了什么是分词:

	- 分词就是将连续的字序列按照一定的规范重新组合成词序列的过程。我们知道，在英文的行文中，单词之间是以空格作为自然分界符的，而中文只是字、句和段能通过明显的分界符来简单划界，唯独词没有一个形式上的分界符, 分词过程就是找到这样分界符的过程.

- 学习了分词的作用:

	- 词作为语言语义理解的最小单元, 是人类理解文本语言的基础. 因此也是AI解决NLP领域高阶任务, 如自动问答, 机器翻译, 文本生成的重要基础环节.

- 学习了流行中文分词工具jieba:

	- 支持多种分词模式: 精确模式, 全模式, 搜索引擎模式

	- 支持中文繁体分词

	- 支持用户自定义词典

- 学习了jieba工具的安装和分词使用.

- 学习了什么是命名实体识别:

	- 命名实体: 通常我们将人名, 地名, 机构名等专有名词统称命名实体. 如: 周杰伦, 黑山县, 孔子学院, 24辊方钢矫直机.

	- 顾名思义, 命名实体识别(Named Entity Recognition，简称NER)就是识别出一段文本中可能存在的命名实体.

- 命名实体识别的作用:

	- 同词汇一样, 命名实体也是人类理解文本的基础单元, 因此也是AI解决NLP领域高阶任务的重要基础环节.

- 学习了什么是词性标注:

	- 词性: 语言中对词的一种分类方法，以语法特征为主要依据、兼顾词汇意义对词进行划分的结果, 常见的词性有14种, 如: 名词, 动词, 形容词等.

	- 顾名思义, 词性标注(Part-Of-Speech tagging, 简称POS)就是标注出一段文本中每个词汇的词性.

- 学习了词性标注的作用:

	- 词性标注以分词为基础, 是对文本语言的另一个角度的理解, 因此也常常成为AI解决NLP领域高阶任务的重要基础环节.

- 学习了使用jieba进行词性标注.