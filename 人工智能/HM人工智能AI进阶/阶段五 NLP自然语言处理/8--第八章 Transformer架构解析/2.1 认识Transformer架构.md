### 学习目标

- 了解Transformer模型的作用.

- 了解Transformer总体架构图中各个组成部分的名称.

### Transformer模型的作用

- 基于seq2seq架构的transformer模型可以完成NLP领域研究的典型任务, 如机器翻译, 文本生成等. 同时又可以构建预训练语言模型，用于不同任务的迁移学习.

- 声明:

	- 在接下来的架构分析中, 我们将假设使用Transformer模型架构处理从一种语言文本到另一种语言文本的翻译工作, 因此很多命名方式遵循NLP中的规则. 比如: Embeddding层将称作文本嵌入层, Embedding层产生的张量称为词嵌入张量, 它的最后一维将称作词向量等.

### Transformer总体架构图

![](https://gitee.com/hxc8/images1/raw/master/img/202407172131443.jpg)

- Transformer总体架构可分为四个部分:

	- 输入部分

	- 输出部分

	- 编码器部分

	- 解码器部分

- 输入部分包含:

	- 源文本嵌入层及其位置编码器

	- 目标文本嵌入层及其位置编码器

![](https://gitee.com/hxc8/images1/raw/master/img/202407172131252.jpg)

- 输出部分包含:

	- 线性层

	- softmax层

![](https://gitee.com/hxc8/images1/raw/master/img/202407172131180.jpg)

- 编码器部分:

	- 由N个编码器层堆叠而成

	- 每个编码器层由两个子层连接结构组成

	- 第一个子层连接结构包括一个多头自注意力子层和规范化层以及一个残差连接

	- 第二个子层连接结构包括一个前馈全连接子层和规范化层以及一个残差连接

![](https://gitee.com/hxc8/images1/raw/master/img/202407172131821.jpg)

- 解码器部分:

	- 由N个解码器层堆叠而成

	- 每个解码器层由三个子层连接结构组成

	- 第一个子层连接结构包括一个多头自注意力子层和规范化层以及一个残差连接

	- 第二个子层连接结构包括一个多头注意力子层和规范化层以及一个残差连接

	- 第三个子层连接结构包括一个前馈全连接子层和规范化层以及一个残差连接

![](https://gitee.com/hxc8/images1/raw/master/img/202407172131562.jpg)

### 小节总结

- 学习了Transformer模型的作用:

	- 基于seq2seq架构的transformer模型可以完成NLP领域研究的典型任务, 如机器翻译, 文本生成等. 同时又可以构建预训练语言模型，用于不同任务的迁移学习.

- Transformer总体架构可分为四个部分:

	- 输入部分

	- 输出部分

	- 编码器部分

	- 解码器部分

- 输入部分包含:

	- 源文本嵌入层及其位置编码器

	- 目标文本嵌入层及其位置编码器

- 输出部分包含:

	- 线性层

	- softmax处理器

- 编码器部分:

	- 由N个编码器层堆叠而成

	- 每个编码器层由两个子层连接结构组成

	- 第一个子层连接结构包括一个多头自注意力子层和规范化层以及一个残差连接

	- 第二个子层连接结构包括一个前馈全连接子层和规范化层以及一个残差连接

- 解码器部分:

	- 由N个解码器层堆叠而成

	- 每个解码器层由三个子层连接结构组成

	- 第一个子层连接结构包括一个多头自注意力子层和规范化层以及一个残差连接

	- 第二个子层连接结构包括一个多头注意力子层和规范化层以及一个残差连接

	- 第三个子层连接结构包括一个前馈全连接子层和规范化层以及一个残差连接