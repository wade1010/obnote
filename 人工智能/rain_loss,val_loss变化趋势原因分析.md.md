
**变化趋势分析：**

1. train loss 不断下降，test loss不断下降，说明网络仍在学习;（最好的）
2. train loss 不断下降，test loss趋于不变，说明网络过拟合；
3. train loss 趋于不变，test loss不断下降，说明数据集100%有问题;（检查dataset）
4. train loss 趋于不变，test loss趋于不变，说明学习遇到瓶颈，需要减小学习率或批量数目;（减少学习率）
5. train loss 不断上升，test loss不断上升，说明网络结构设计不当，训练超参数设置不当，数据集经过清洗等问题；（最不好的情况）
6. train_loss 不断下降， test_loss 不断上升，和第2种情况类似说明网络过拟合了。

**应对神经网络过拟合的方法包括：**

- **简化模型。**通过减少神经网络层数或神经元数量来降低模型复杂度，从而减少过拟合风险。同时，注意调整神经网络中各层的输入和输出尺寸。
- **数据增强。**通过图像翻转、平移、旋转、缩放、改变亮度、添加噪声等技术，生成新的训练数据，增加数据集规模，减少过拟合。
- **正则化。**在损失函数中添加惩罚项，如L1正则化和L2正则化，以降低模型复杂度，减少过拟合。
- **早停法。**在训练过程中，当模型在验证集上的性能开始下降时，提前终止训练，避免过拟合。
- **集成学习。**通过结合多个模型的预测结果，来减少单模型的过拟风险。
- **批量归一化。**使用批量归一化技术，减少内部协变量偏移，有助于提高模型的泛化能力。
- **Dropout。**在训练过程中随机忽略一些神经元，减少模型对特定神经元的依赖，从而降低过拟风险。
- **迁移学习。**利用在相关领域预训练好的模型，在其上进行微调，可以提高模型性能，减少过拟风险。

通过上述方法，可以有效减少神经网络的过拟合现象，提高模型的泛化能力。

作者：初识CV  
链接：https://www.zhihu.com/question/451883491/answer/3478581966  
来源：知乎  
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。  