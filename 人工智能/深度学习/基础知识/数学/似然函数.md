![](https://gitee.com/hxc8/images2/raw/master/img/202407172204460.jpg)

![](https://gitee.com/hxc8/images2/raw/master/img/202407172204819.jpg)

![](https://gitee.com/hxc8/images2/raw/master/img/202407172204383.jpg)

极大似让函数

![](images/WEBRESOURCE94e628967aff720f157ab7d86f5b842b截图.png)

![](https://gitee.com/hxc8/images2/raw/master/img/202407172205403.jpg)

![](https://gitee.com/hxc8/images2/raw/master/img/202407172205909.jpg)

logAB=logA+logB

一般我们都要对似然函数取对数，因为取完对数之后就好解了，

一般是求什么样的theta能达到最大值，求的不是极大值，而是求什么样的theta能够达到这样的极大值。我们求的是一个极值点。而不是一个极值。

优化下，在当前函数前面加上ln，ln函数单调递增，没有拐点，对函数极值必然发生变化，theta取不同值，它的本身似然值和对数值都不一样了， 但是极值点事没变的，既然求值点没变，求解目标也没变

所以就可以把似然函数求解转换为对数似然求解的问题。

第一步：先构造似然函数，

第二步：对似然函数取一个对数，

第三步：求偏导

机器学习通常目标是求最终一个解是什么样一个参数得到的。说白了就是求参数。

![](https://gitee.com/hxc8/images2/raw/master/img/202407172205943.jpg)

![](https://gitee.com/hxc8/images2/raw/master/img/202407172205308.jpg)

![](https://gitee.com/hxc8/images2/raw/master/img/202407172205578.jpg)