fasttext可以在词向量的训练和句子分类上取得非常好的表现，尤其表现在对罕见词进行了字符粒度上的处理。



每个单词除了单词本身外还被表示为多个字符级别的n-grams（有时也称为N元模子）。例如，对于单词matter，当n = 3时，fasttext对该词对字符ngram就表示为<ma, mat, att, tte, ter, er>。其中<和>是作为边界符号被添加，来将一个单词的ngrams与单词本身区分开来。再举个例子，如果单词mat属于我们的词汇表，则会被表示为<mat>。这么做刚好让一些短词以其他词的ngram出现，有助于更好学习到这些短词的含义。从本质上讲，这可以帮助你捕捉后缀/前缀的含义。



可以通过-minn和-maxn这两个参数来控制ngrams的长度，这两个标志分别决定了ngrams的最小和最大字符数，也即控制了ngrams的范围。这个模型被认为是一个词袋模型，因为除了用于选择n-gram的滑动窗口外，它并没有考虑到对单词的内部结构进行特征选择。它只要求字符落在窗口以内，但并不关心ngrams的顺序。你可以将这两个值都设为0来完全关闭n-gram，也就是不产生n-gram符号，单纯用单词作为输入。当您的模型中的“单词”不是特定语言的单词时或者说字符级别的n-gram没有意义的时候，这会变得很有用。最常见的例子是当您将id作为您的单词输入。在模型更新期间，fastText会学习到每个ngram以及整个单词符号的权重。



除了自动删减过程，对于已经存在于词汇表里的单词的最小计数是通过使用-minCount和-minCountLabel(用于监督训练)这两个参数来控制的。基于这两个参数的删减在整个训练文件被处理之后进行。如果单词表的总数已经触发了前面所说的因哈希值太大发生的自动删减，那么您的词典可能就需要手动设置一个较高值的minCount阈值了。但无论如何，你都必须手动指定minCount阈值，才能确保较低词频的单词不会被用作输入的一部分。







minCount  过滤掉低频次，频次小于这个数的值过滤掉

dim 向量维度，可以控制模型大小  dim=100时1.74G   dim=50时 947MB  dim=10 时311MB