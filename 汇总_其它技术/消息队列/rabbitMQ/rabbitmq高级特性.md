1. ACK确认机制
2. 如何保证消息百分之百投递成功
3. 幂等性
4. return机制
5. 限流
6. 重回队列
7. TTL
8. 死信队列


解决的问题：

- 生产者消息送达失败
- 重复消费
- 消息没有成功消费
- 消息N年后一直没被销毁
- 高并发
- 消息丢失后无法找回


#### ACK确认机制图

![image](D:/download/youdaonote-pull-master/data/Technology/消息队列/rabbitMQ/images/48196image.png)


#### 百分之百投递成功

##### 方案1
![image](https://gitee.com/hxc8/images7/raw/master/img/202407190740208.jpg)

比如

step1：存储订单消息（创建订单），业务数据入库，消息也入库。缺点:需要持久化两次。（status:0）

step2：在step1成功的前提下，发送消息

step3：Broker收到消息后，confirm给我们的生产端。Confirm Listener异步监听Broker回送的消息。

step4：抓取出指定的消息，更新（status=1），表示消息已经投递成功。

step5：分布式定时任务获取消息状态，如果等于0则抓取数据出来。

step6：重新发送消息

step7：重试限制设置3次。如果消息重试了3次还是失败，那么（status=2）,认为这个消息就是失败的。

查询这些消息为什么失败，可能需要人工去查询。

假设step2执行成功，step3由于网络闪断。那么confirm将永远收不到消息，那么我们需要设定一个规则：

例如：在消息入库的时候，设置一个临界值 timeout=5min，当超过5min之后，就将这条数据抓取出来。
或者写一个定时任务每隔5分钟就将status=0的消息抓取出来。可能存在小问题：消息发送出去，定时任务又正好刚执行，Confirm还未收到，定时任务就会执行，会导致消息执行两次。
更精细化操作：消息超时容忍限制。confirm在2-3分钟内未收到消息，则重新发送。

保障MQ我们思考如果第一种可靠性投递，在高并发的场景下是否合适？
第一种方案对数据有两次入库，一次业务数据入库，一次消息入库。这样对数据的入库是一个瓶颈。
其实我们只需要对业务进行入库。

消息的延迟投递，做二次确认，回调检查
这种方式并不一定能保证100%成功，但是也能保证99.99%的消息成功。如果遇到特别极端的情况，那么就只能需要人工去补偿，或者定时任务去做。
第二种方式主要是为了减少对数据库的操作。

##### 方案2
![image](https://gitee.com/hxc8/images7/raw/master/img/202407190740723.jpg)


这样做的目的：少做了一次DB存储。关注点并不是百分百的投递成功，而是性能


### 幂等性

#### 什么是幂等性
比如数据库的乐观锁,在执行更新操作前，先去数据库查询version,然后执行更新语句,以version作为条件如果执行更新时有其他人先更新了这张表的数据，那么这个条件就不生效了,也就不会执行操作了,通过这种乐观锁的机制来保障幂等性.


#### 什么是Con-幂等性
在业务高峰期最容易产生消息重复消费问题，当Con消费完消息时,在给Pro返回ack时由于网络中断,导致Pro未收到确认信息该条消息就会重新发送并被Con消费,但实际上该消费者已成功消费了该条消息,这就造成了重复消费.
而Con -幂等性,即消息不会被多次消费，即使我们收到了很多-样的消息.


##### 解决方案1 唯一ID+指纹码

##### 核心:利用数据库主键去重

●唯一ID:业务表的主键

●指纹码:为了区别每次正常操作的码，每次操作时生成指纹码;可以用时间戳+业务编号或者标志位(具体视业务场景而定)


```
SELECT COUNT(1) FROM T ORDER WHERE ID =唯一ID and IS_ CONSUM= 指纹码
```


●优势实现简单

●弊端高并发下有数据库写入的性能瓶颈

●解决方案根据ID进行分库分表算法路由

###### 小结

首先我们需要根据消息生成一个全局唯- -ID, 然后还需要加上一个指纹码。这个指纹码它并不一定是系统去生成
的，而是- -些外部的规则或者内部的业务规则去拼接，它的目的就是为了保障这次操作是绝对唯一的。
将ID +指纹码拼接好的值作为数据库主键,就可以进行去重了。即在消费消息前呢，先去数据库查询这条消息的指纹码标识是否存在,没有就执行insert操作，如果有就代表已经被消费了，就不需要管了



##### 解决方案2

利用Redis的原子性去实现，实现去重，实现幂等性操作。需要考虑的问题，第一个问题是我们是否要进行数据落库，如果落库的话，关键解决的问题是数据库和缓存如何做到原子性。第二个问题，如果不进行落库，那么都存储到缓存中，如何设置定时同步的策略。


### Return消息机制

Return Listener用于处理一些不可路由的消息。也是生产段添加的一个监听。

　　我们的消息生产者，通过指定一个Exchange和Routingkey，把消息送达到某一个队列中去，然后我们的消费者监听队列，进行消息处理操作。但是在某些情况下，如果我们在发送消息的时候，指定的路由key路由不到，这个时候如果我们需要监听这种不可达的消息，就要使用Return Listener。

　　Return消息机制，在基础api中有一个关键的配置项。Mandatory，如果为true，则监听器会接收到路由不可达的消息，然后进行后续处理，如果为false，那么broker端自动删除该消息。


![image](https://gitee.com/hxc8/images7/raw/master/img/202407190740149.jpg)



#### RabbitMQ消费端的限流策略

什么是消费端的限流。假设一个场景，首先，我们RabbitMQ服务器有上万条未处理的消息，我们随便打开一个消费者客户端，会出现下面的情况。巨量的消息瞬间全部推送过来，但是我们单个客户端无法同时处理这么多数据。

1. 消费端限流，RabbitMQ提供了一种Qos（quality of service服务质量保证）功能，即在非自动确认消息的前提下，如果有一定数据的消息堆积，可以设置一个限制，我们不去更新消费，不去做ack，不去做确认机制。如果有一定数目的消息（通过基于consume或者channel设置Qos的值），消息未被确认前，不进行消费新的消息。Rabbitmq有两种签收模式，一种是自动签收，一种是手动签收。如果做消费端限流的话，不能设置自动签收模式，即autoack=false。

2. 消费端的方法void BasicQos(unit prefetchSize,ushort prefetchCount,bool global);
    - 参数1是prefetchSize消息大小的限制，设置为0，不做大小限制。
    
    - 参数2是prefetchCount一次最多可以处理的消息，会告诉RabbitMQ不要同时给一个消费者推送多于N个消息，即一旦有N个消息还没有ack，则该consume将block掉，直到有消息ack。
    
    - 参数3是global是什么方式应用的，true表示channel的级别，false表示consume进行限制，true或者false是否将上面设置应用于channel简单点说，就是上面限制是channel级别的还是consumer级别。

3. 注意：prefetchSize和global这两项，rabbitmq没有实现，暂且不研究prefetch_count在no_ask=false的情况下生效，即在自动应答（自动签收）的情况下这两个值是不生效的。

4. 消费端的限流策略，开发步骤如下所示：

第一步，限流方式，第一件事就是autoAck设置为false。

　　　　
第二步，channel.basicQos(0,1,false);

　　　　
第三步，手动确认，channel.basicAck(envelope.getDeliveryTag(),flase);参数1是deliveryTag，表示这一条消息已经处理完了，可以给一下条了，参数2是不批量签收，我们一条一条进行签收。

### Rabbitmq的消费端ACK与重回队列。

　　答：消费端可以进行手动的ACK和NACK。区分与ack自动确认签收，手动的ACK是代表消息确认了，消息已经收到了，确认了会给Broker端发送一个请求，说我已经收到了。手动NACK是代表了消息未进行确认，消息未收到或者处理失败了，Broker端将未收到的消息重新发送一遍。消费端进行消费的时候，如果由于业务异常我们可以进行日志的记录，然后进行补偿。如果由于服务器宕机等严重问题，那我们就需要手工进行ACK保障消费端消息成功。

　　消费端的重回队列，消息未被处理成功，将该消息重新发送给Broker，消费端重回队列是为了对没有处理成功的消息，把消息重新会递给Broker。一般我们在实际应用中，都会关闭重回队列，也就是设置为False。

### RabbitMQ的TTL队列或者消息

TTL是Time To Live的缩写，也就是生存时间。

　　RabbitMQ支持消息的过期时间，在消息发送的时候可以进行指定。RabbitMQ支持队列的过期时间，从消息入队列开始计算，只要超过了队列的超时时间配置，那么消息会自动的清除。

### 死信队列，DLX，Dead-Letter-Exchange。

1. RabbitMQ的死信队列是路由到交换机上面的，RabbitMQ的死信队列是和Exchange、队列息息相关的。利用DLX，当消息在一个队列中变成死信（dead message，即这个消息没有任何消费者消费）之后，它能被重新publish到另一个Exchange，这个Exchange就是DLX（死信队列，Dead-Letter-Exchange）。
2. 消息变成死信有以下几种情况。
        
        a、当消息被拒绝（basic.reject/basic.nack）并且requeue=false。
        
        
        b、消息TTL（TTL是Time To Live的缩写，也就是生存时间）过期。
        
        
        c、当队列达到了最大长度。



3. DLX也是一个正常的Exchange，和一般的Exchange没有区别，它能在任何的队列上被指定，实际上就是设置某个队列的属性。当这个队列中有死信的时候，RabbitMQ就会自动的将这个消息重新发布到设置的Exchange上去，进而被路由到另一个队列。可以监听这个队列中消息做相应的处理，这个特性可以弥补RabbitMQ3.0以前支持的immediate参数的功能。

4. 死信队列设置，首先需要设置死信队列的exchange和queue，然后进行绑定。



    第一步、Exchange:dlx.exchange。死信队列就是一个正常的交换机Exchange。
    
    
    第二步、Queue:dlx.queue。需要将队列和这个交换机Exchange进行绑定。
    
    
    第三步、RoutingKey:#。任何的路由key都可以进行绑定。然后我们进行正常声明交换机，队列，绑定，只不过我们需要在队列加上一个参数即可：arguments.put("x-dead-letter-exchange","dlx.exchange");最后需要设置一个监听来监听这个队列。这样消息在过期、requeue、队列在达到最大长度的时候，消息就可以直接路由到死信队列了。