4K的超高清转播，这些技术上的创新给很多球迷朋友们带来非常好的体验。

首先第一点，本地大赛上首次启用了只能图像数据分析系统，他们用的是索尼的HDC-4300作为拍摄主力相机。

属于4K相机，4K标准就是3840X2160像素，类似于4个1080P，非常的高清。

因为更多的数据细节为为后面的AI处理做铺垫。

当年老秦做得海思3518EV200真的是小儿科，CPU的处理能力撑死也就是720P，这样一个系统，就是让球员们在场上的表现，动作，神情，都会以数据指标、图形或者数据图表的形式，实时传递给手机或者电视前的球迷们。

这个智能图像数据分析系统中包含了类似于赛况、期望进球数等还有其它一些指标。

接下来聊聊一般的数据走向，其实拍摄的视频最原始的数据是光信号，然后把光信号转换为电信号，这里面其实数据数电和模电的知识，另外还有信号处理技术，它们不涉及到写C语言代码。

比如像CCD、CMOS这些成像原理，然后通过模数转化器，也就是我们所说的ADC，转化为数字信号后，一般是通过I2C协议传到视频处理模块，这个I2C就要你自己去用C语言写代码了，主要是写驱动。其实这时候，我们就拿到了一些视频数据，肯定要编码，不然一帧全彩的4K的图片就差不多有200兆了。

如果说是每秒60帧，那一秒就要传输12G的数据，那肯定扛不住，所以视频必须要通过压缩编码才能进行传输 。

然后将采集的这些视频进行一系列的定制化的图像处理、AI处理、大量的数据计算。这对CPU和时间复杂度要求也特别高、压缩编码后，然后走推流，CDN分发。将压缩过的视频流通过网络传输出去，这块是推流。

拉流什么的就是我们所说的音视频传输技术，再接着就是客户端拉流，进行一些socket通信，然后解码，后面进行渲染，再实时播放。

在这个过程里面，摄像头设局采集啊，肯定是C语言写的，音视频服务器、音视频解码、音视频传输，包括安卓客户端拉流的SDK的jni层都是用C++实现的。

第二大技术，半越位技术

因为在踢球的过程中，越位是经常会出现有争议的判罚，这次世界杯用的是半自动越位技术来减少争议，在足球里面安装传感器，以高频率发送数据，高精度的检测踢球点，判定球员传球瞬间，配合摄像头来跟踪每个球员数据点位，来计算他所处的准确位置，这个就相当于是以传感器驱动的自动的越位警报系统，并且还可以同时生成3D动画，然后通过转播镜头和现场大屏把数据推过去，向球迷展示细节，整个过程只需要几秒钟，是不是越位，或者说在那里越位，这个在直播里面非常的清楚。这就是我们所说的机器视觉和深度学习。

机器视觉就是用机器，比如那一系列的传感器，来代替人眼做测量和判断。

深度学习数据机器学习的一种，模拟人脑，对一写具体的示例，分析和学习的一个神经网络，就是模仿人脑机制来解释数据，，比如说越位的机器判定，肯定是通过很多次的深度学习来完成的，整个半自动越位技术真的就是将AI物联网技术展示的淋漓尽致，有AI有嵌入式有服务器有音视频，这些领域根本离不开C++，像半自动越位技术的嵌入式传感器数据采集，这块肯定是C语言写的，机器学习要用到opencv，TensorFlow，这块都是C++去实现的 