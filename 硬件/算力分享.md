### 一、什么是算力?

算力的字面意思，大家都懂，就是计算能力（Computing Power）。

算力是指计算机系统、芯片、软件等计算设备或系统在特定时间内能够完成的计算任务数量或计算速度的指标。通常以浮点运算次数每秒（FLOPS/s）或者每秒亿次浮点运算（GFLOPS）来衡量。

### 二、算力的发展历史

远古时期，我们的原始工具是草绳、石头。后来，随着文明的进步，我们有了算筹（一种用于计算的小棍子）、算盘等更为实用的算力工具，算力水平不断提升。

到了20世纪40年代，我们迎来了算力革命。

1946年2月，世界上第一台数字式电子计算机ENIAC诞生，标志着人类算力正式进入了数字电子时代。

![](https://gitee.com/hxc8/images5/raw/master/img/202407180002096.jpg)

ENIAC，1946年

再后来，随着半导体技术的出现和发展，我们又进入了芯片时代。芯片成为了算力的主要载体。

![](https://gitee.com/hxc8/images5/raw/master/img/202407180002805.jpg)

世界上第一个集成电路（芯片），1958年

时间继续推移。

到了20世纪70-80年代，芯片技术在摩尔定律的支配下，已经取得了长足进步。芯片的性能不断提升，体积不断减小。终于，计算机实现了小型化，PC（个人电脑）诞生了。

![](https://gitee.com/hxc8/images5/raw/master/img/202407180002065.jpg)

世界上第一台PC（IBM5150），1981年

PC的诞生，意义极为深远。它标志着IT算力不再仅为少数大型企业服务（大型机），而是昂首走向了普通家庭和中小企业。它成功打开了全民信息时代的大门，推动了整个社会的信息化普及。

在PC的帮助下，人们充分感受到IT算力带来的生活品质改善，以及生产效率提升。PC的出现，也为后来互联网的蓬勃发展奠定了基础。

进入21世纪后，算力再次迎来了巨变。

这次巨变的标志，是云计算技术的出现。

![](https://gitee.com/hxc8/images5/raw/master/img/202407180002657.jpg)

云计算，Cloud Computing

在云计算之前，人类苦于单点式计算（一台大型机或一台PC，独立完成全部的计算任务）的算力不足，已经尝试过网格计算（把一个巨大的计算任务，分解为很多的小型计算任务，交给不同的计算机完成）等分布式计算架构。

云计算，是分布式计算的新尝试。它的本质，是将大量的零散算力资源进行打包、汇聚，实现更高可靠性、更高性能、更低成本的算力。

具体来说，在云计算中，中央处理器（CPU）、内存、硬盘、显卡（GPU）等计算资源被集合起来，通过软件的方式，组成一个虚拟的可无限扩展的“算力资源池”。

用户如果有算力需求，“算力资源池”就会动态地进行算力资源的分配，用户按需付费。

相比于用户自购设备、自建机房、自己运维，云计算有明显的性价比优势。

![](https://gitee.com/hxc8/images5/raw/master/img/202407180002648.jpg)

云计算数据中心

算力云化之后，数据中心成为了算力的主要载体。人类的算力规模，开始新的飞跃。

### 三、 算力的单位

算力既然是一个“能力”，当然就会有对它进行强弱衡量的指标和基准单位。大家比较熟悉的单位，应该是FLOPS、TFLOPS等。

其实，衡量算力大小的指标还有很多，例如MIPS、DMIPS、OPS等。

![](https://gitee.com/hxc8/images5/raw/master/img/202407180002274.jpg)

MFLOPS、GFLOPS、TFLOPS、PFLOPS等，都是FLOPS的不同量级。具体关系如下：

![](https://gitee.com/hxc8/images5/raw/master/img/202407180002728.jpg)

1 TFLOPS相当于1000 GFLOPS、1 GFLOPS相当于1000 MFLOPS（每秒百万次浮点运算）

算力对比表格：

![](https://gitee.com/hxc8/images5/raw/master/img/202407180002038.jpg)

### 四、算力分类

我们将算力分为两大类，分别是通用算力和专用算力。

![](https://gitee.com/hxc8/images5/raw/master/img/202407180002297.jpg)

像x86这样的CPU处理器芯片，就是通用芯片。它们能完成的算力任务是多样化的，灵活的，但是功耗更高。

而专用芯片，主要是指FPGA和ASIC。

FPGA，是可编程集成电路。它可以通过硬件编程来改变内部芯片的逻辑结构，但软件是深度定制的，执行专门任务。

ASIC，是专用集成电路。顾名思义，它是为专业用途而定制的芯片，其绝大部分软件算法都固化于硅片。

ASIC能完成特定的运算功能，作用比较单一，不过能耗很低。FPGA，介于通用芯片和ASIC之间。

![](https://gitee.com/hxc8/images5/raw/master/img/202407180002748.jpg)

以比特币挖矿为例：

以前，人们都是用PC（x86通用芯片）挖矿，

后来越挖难度越大，算力不够。于是，开始使用显卡（GPU）去挖矿。

再后来，显卡的能耗太高，挖出来的币值还抵不上电费，就开始采用FPGA和ASIC集群阵列挖矿。

专用芯片：

![](https://gitee.com/hxc8/images5/raw/master/img/202407180002750.jpg)

现在经常听说的“算力卸载”，其实不是删除算力，而是把很多计算任务（例如虚拟化、数据转发、压缩存储、加密解密等），从CPU转移到NPU、DPU等芯片上，减轻CPU的算力负担。

### 四、算力的应用

- 科学计算

- 人工智能和机器学习

- 加密货币挖矿

- 游戏和虚拟现实